{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab7cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed16f7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Good product.. I thought its not comfort to me...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good quality and quick delivery. Material is s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nice product from Butterfly used a good qualit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>It's Very useful and Time saver.  But it's ver...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I was ordering this for my motherShe loved it ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>9975</td>\n",
       "      <td>Well and good... Handle like arrangement may h...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>9976</td>\n",
       "      <td>Wow awesome product üòçüòçREAD MORE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>9977</td>\n",
       "      <td>Good.... Nothing mixer for batter then...READ ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>9978</td>\n",
       "      <td>It goodREAD MORE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>9979</td>\n",
       "      <td>Its worthy to purchase instead of buying that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6036 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                             review  rating\n",
       "0              0  Good product.. I thought its not comfort to me...       5\n",
       "1              1  Good quality and quick delivery. Material is s...       5\n",
       "2              2  Nice product from Butterfly used a good qualit...       4\n",
       "3              3  It's Very useful and Time saver.  But it's ver...       5\n",
       "4              4  I was ordering this for my motherShe loved it ...       5\n",
       "...          ...                                                ...     ...\n",
       "6031        9975  Well and good... Handle like arrangement may h...       4\n",
       "6032        9976                    Wow awesome product üòçüòçREAD MORE       1\n",
       "6033        9977  Good.... Nothing mixer for batter then...READ ...       3\n",
       "6034        9978                                   It goodREAD MORE       3\n",
       "6035        9979  Its worthy to purchase instead of buying that ...       1\n",
       "\n",
       "[6036 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"reviews.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3911b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27399118",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8663064c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\mounika\n",
      "[nltk_data]     katla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\mounika\n",
      "[nltk_data]     katla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\mounika\n",
      "[nltk_data]     katla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing neccesary libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "    \n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92835f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    \n",
    "    \n",
    "    # removing READ MORE word\n",
    "    sentance=re.sub(\"READ MORE\",\"\",text) \n",
    "    \n",
    "    # removing urls\n",
    "    sentance=re.sub(\"https?://\\S+|www\\.S\\+\",\"\",sentance) \n",
    "    \n",
    "    # removing html tags\n",
    "    sentace=re.sub(r\"<.*?>\",\"\",sentance) \n",
    "    \n",
    "    # removing special characters and numbers\n",
    "    sentance=re.sub(\"[^A-Za-z]\",\" \",sentance) \n",
    "    \n",
    "    # convert the sentance into uniform case\n",
    "    sentance=sentance.lower()\n",
    "    \n",
    "    # convert the sentance into word token\n",
    "    tokens=sentance.split()\n",
    "    \n",
    "    # removing stopwords\n",
    "    clean_tokens=[t for t in tokens if not t in stopwords.words(\"english\")]\n",
    "    \n",
    "    # lemmatize the words\n",
    "    clean_tokens=[lemmatizer.lemmatize(word) for word in clean_tokens]\n",
    "    \n",
    "    # return the lemmatize the word in sentence format\n",
    "    return \" \".join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e3b3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemsentances\"]=df[\"review\"].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1cd4634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>lemsentances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good product.. I thought its not comfort to me...</td>\n",
       "      <td>5</td>\n",
       "      <td>good product thought comfort really comfort cook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good quality and quick delivery. Material is s...</td>\n",
       "      <td>5</td>\n",
       "      <td>good quality quick delivery material stronger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice product from Butterfly used a good qualit...</td>\n",
       "      <td>4</td>\n",
       "      <td>nice product butterfly used good quality plast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's Very useful and Time saver.  But it's ver...</td>\n",
       "      <td>5</td>\n",
       "      <td>useful time saver sharp blade beawar cleaning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was ordering this for my motherShe loved it ...</td>\n",
       "      <td>5</td>\n",
       "      <td>ordering mothershe loved lot work fluently cut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>Well and good... Handle like arrangement may h...</td>\n",
       "      <td>4</td>\n",
       "      <td>well good handle like arrangement may help bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>Wow awesome product üòçüòçREAD MORE</td>\n",
       "      <td>1</td>\n",
       "      <td>wow awesome product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>Good.... Nothing mixer for batter then...READ ...</td>\n",
       "      <td>3</td>\n",
       "      <td>good nothing mixer batter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>It goodREAD MORE</td>\n",
       "      <td>3</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>Its worthy to purchase instead of buying that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>worthy purchase instead buying bm juicer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6036 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  rating  \\\n",
       "0     Good product.. I thought its not comfort to me...       5   \n",
       "1     Good quality and quick delivery. Material is s...       5   \n",
       "2     Nice product from Butterfly used a good qualit...       4   \n",
       "3     It's Very useful and Time saver.  But it's ver...       5   \n",
       "4     I was ordering this for my motherShe loved it ...       5   \n",
       "...                                                 ...     ...   \n",
       "6031  Well and good... Handle like arrangement may h...       4   \n",
       "6032                    Wow awesome product üòçüòçREAD MORE       1   \n",
       "6033  Good.... Nothing mixer for batter then...READ ...       3   \n",
       "6034                                   It goodREAD MORE       3   \n",
       "6035  Its worthy to purchase instead of buying that ...       1   \n",
       "\n",
       "                                           lemsentances  \n",
       "0      good product thought comfort really comfort cook  \n",
       "1     good quality quick delivery material stronger ...  \n",
       "2     nice product butterfly used good quality plast...  \n",
       "3     useful time saver sharp blade beawar cleaning ...  \n",
       "4     ordering mothershe loved lot work fluently cut...  \n",
       "...                                                 ...  \n",
       "6031  well good handle like arrangement may help bet...  \n",
       "6032                                wow awesome product  \n",
       "6033                          good nothing mixer batter  \n",
       "6034                                               good  \n",
       "6035           worthy purchase instead buying bm juicer  \n",
       "\n",
       "[6036 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2290f3",
   "metadata": {},
   "source": [
    "## spliting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ac8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[[\"lemsentances\"]]\n",
    "y=df[[\"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcdf8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5225048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain,xTest,yTrain,yTest=train_test_split(X,y,\n",
    "                                          test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4cec59",
   "metadata": {},
   "source": [
    "# creating a model for text data using CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e6ff8",
   "metadata": {},
   "source": [
    "## CountVectorizer for Bag of Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d52f0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvectorizer=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beed5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "countXTrain=countvectorizer.fit_transform(xTrain[\"lemsentances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80e2577a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4527x2123 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19369 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countXTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98439881",
   "metadata": {},
   "outputs": [],
   "source": [
    "countXTest=countvectorizer.transform(xTest[\"lemsentances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1034a89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1509x2123 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6077 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countXTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fad978",
   "metadata": {},
   "source": [
    "### creating a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817246dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac6c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mounika katla\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "LR.fit(countXTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47dff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrainpred=LR.predict(countXTrain)\n",
    "YTestpred=LR.predict(countXTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as acs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea927034",
   "metadata": {},
   "outputs": [],
   "source": [
    "acs(yTrain,YTrainpred),acs(yTest,YTestpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba0375",
   "metadata": {},
   "source": [
    "## CountVectorizer for Bag of Uni-Bi grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15030a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvectorizer=CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "countXTrain=countvectorizer.fit_transform(xTrain[\"lemsentances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8982c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "countXTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da76514",
   "metadata": {},
   "outputs": [],
   "source": [
    "countXTest=countvectorizer.transform(xTest[\"lemsentances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "countXTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a67f2e",
   "metadata": {},
   "source": [
    "### creating a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1764a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ecdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(countXTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a9b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrainpred=LR.predict(countXTrain)\n",
    "YTestpred=LR.predict(countXTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acs(yTrain,YTrainpred),acs(yTest,YTestpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e162148",
   "metadata": {},
   "source": [
    "# creating a model for text data using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb48bc43",
   "metadata": {},
   "source": [
    "## TfidfVectorizer for Bag of Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fdb91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfVec=TfidfVectorizer()\n",
    "\n",
    "tfidfXTrain=tfidfVec.fit_transform(xTrain[\"lemsentances\"])\n",
    "\n",
    "tfdifXTest=tfidfVec.transform(xTest[\"lemsentances\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c56926",
   "metadata": {},
   "source": [
    "### creating a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR=LogisticRegression()\n",
    "LR.fit(tfidfXTrain,yTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b2908",
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrainpred=LR.predict(tfidfXTrain)\n",
    "YTestpred=LR.predict(tfdifXTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c6193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acs(yTrain,YTrainpred),acs(yTest,YTestpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd91130",
   "metadata": {},
   "source": [
    "## TfidfVectorizer for Bag of Uni-Bi grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262e216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfVec=TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "tfidfXTrain=tfidfVec.fit_transform(xTrain[\"lemsentances\"])\n",
    "\n",
    "tfdifXTest=tfidfVec.transform(xTest[\"lemsentances\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a99847",
   "metadata": {},
   "source": [
    "### creating a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bd12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR=LogisticRegression()\n",
    "LR.fit(tfidfXTrain,yTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b61aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrainpred=LR.predict(tfidfXTrain)\n",
    "YTestpred=LR.predict(tfdifXTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44298414",
   "metadata": {},
   "outputs": [],
   "source": [
    "acs(yTrain,YTrainpred),acs(yTest,YTestpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676dcc5",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
